## Grayscale conversion

*A Grayscale* in an image is where the value of each pixel is a single sample that represents only an amount of light; that is, it carries only intensity information. Grayscale images, a kind of monochrome in black and white or gray, are made up exclusively of shades of gray. Contrast ranges from black at the weakest intensity to white at the strongest.


### Problem Statement
Apply a grayscale conversion to an image and a video using RGB averaging and Luma.

### Background

The RGB color model is an additive color model in which red, green, and blue light are added together in various ways to reproduce a broad array of colors. The name of the model comes from the initials of the three additive primary colors, red, green, and blue.  

The main purpose of the RGB color model is for the sensing, representation, and display of images in electronic systems, such as televisions and computers, though it has also been used in conventional photography. Before the electronic age, the RGB color model already had a solid theory behind it, based in human perception of colors.

> :P5 sketch=/docs/sketches/workshop1/w1/rgb.js, width=775, height=255

In computing, the grayscale can be computed through rational numbers, image pixels are usually quantized to store them as unsigned integers, to reduce the required storage and computation. Some early grayscale monitors can only display up to sixteen different shades, which would be stored in binary form using 4 bits. But today grayscale images (such as photographs) intended for visual display (both on screen and printed) are commonly stored with 8 bits per sampled pixel. This pixel depth allows 256 different intensities (i.e., shades of gray) to be recorded, and also simplifies computation as each pixel sample can be accessed individually as one full byte. However, if these intensities were spaced equally in proportion to the amount of physical light they represent at that pixel (called a linear encoding or scale), the differences between adjacent dark shades could be quite noticeable as banding artifacts, while many of the lighter shades would be "wasted" by encoding a lot of perceptually-indistinguishable increments. Therefore, the shades are instead typically spread out evenly on a gamma-compressed nonlinear scale, which better approximates uniform perceptual increments for both dark and light shades, usually making these 256 shades enough (just barely) to avoid noticeable increments.  

In order to convert an image to grayscale, there are different approaches, some more intuitive than others. For this workshop, two will be discussed: RGB average and Luma.

### Methodology

#### RGB Average

The average of the channels (RGB) is an intuitive approach, which seeks to calculate the average of the 3 channels (red, green and blue) for each pixel of the image, obtaining a single value, which will be assigned in each one of the 3 channels of the corresponding pixel of the new generated image. This combines the lightness or luminance contributed by each color band into a reasonable gray 

The simplest definition is just the arithmetic mean, i.e. average, of the three components, in the HSI model called intensity. This is simply the projection of a point onto the neutral axis—the vertical height of a point in our tilted cube. The advantage is that, together with Euclidean-distance calculations of hue and chroma, this representation preserves distances and angles from the geometry of the RGB cube.approximation.

> :Formula align=center
>
> ```
> I = avg(R,G,B) = \frac{1}{3} (R +  G +  B) \\
> ```


![Process](../sketches/workshop1/w1/approaches.png)


#### Luma

To our eyes green looks about ten times brighter than blue. Through many repetitions of carefully designed experiments, psychologists have figured out how different we perceive the luminance or red, green, and blue to be. They have provided us a different set of weights for our channel averaging to get total luminance.

Luma is the weighted average of gamma-corrected R, G, and B, based on their contribution to perceived lightness, long used as the monochromatic dimension in color television broadcast. For sRGB, the Rec. 709 primaries yield Y′709, digital NTSC uses Y′601 according to Rec. 601 and some other primaries are also in use which result in different coefficients. Y'709 will be used for this workshop.

> :Formula align=center
>
> ```
> Y_{709} = 0.2126 * R + 0.7152 * G + 0.0722 * B \\
> ```

### Code
This program is written in ```javascrip``` and uses a very powerfull drawing library called [p5.js](https://p5js.org).


#### Convertions - Images

In order to apply each conversion (RGB Average and Luma) on the image, a function was designed to iterate over each pixel of the image and calculate the previously presented formulas. The new matrix that is returned contains only one value for each pixel, unlike the matrix of the original image, which contains 4 values for each [red, green, blue, alpha].


```javascript
/**
 * 
 * @param {*} img : image to be processed. Function changes the same reference to image. 
 * @param {*} convertion : type of convertion. 
 * @returns 
 */
function applyConvertion (img, convertion){
  let newImage = []; // Stores values in matrix : [[row1], [row2], ..., [rowN]]
  let conv;

  if (convertion === 'avg') {
    conv = (pixel) => (red(pixel) +  green(pixel) + blue(pixel))/3;
  } else {
    conv = (pixel) => 0.2126 * red(pixel) + 0.7152 * green(pixel) + 0.0722 * blue(pixel);
  }

  img.loadPixels();
  for (let j = 0; j < img.height; j++) {
    let row = [] // Single row of the matrix
    for (let i = 0; i < img.width; i++) {
      row.push(conv(img.get(i, j))); // Apply to every pixel in image
    }
    newImage.push(row); 
  }
  return { 
    values: newImage 
  }
}
```

#### Draw convertions

The images are converted and drawed on the canvas in the setup function, knowing that it only needs to be done once.

```javascript
function setup() {
  createCanvas(775, 255);
  img_original.resize(250, 250);
  image(img_original, 0, 0);

  let values = [applyConvertion(img_original, 'avg').values, applyConvertion(img_original, 'luma').values];

  for (let i=0; i < values.length; i++) {
    let curr = values[i]
    let img = createImage(250, 250);
    img.loadPixels();
    for (let i = 0; i < img.width; i++) {
      for (let j = 0; j < img.height; j++) {
        img.set(i, j, color(curr[j][i]));
      }
    }
    img.updatePixels();
    image(img, 260*(i+1), 0);
  }

}
```

#### Results 

On the canvas is drawn: the original image, the image with RGB average and the image with Luma,  respectively.


# > :P5 sketch=/docs/sketches/workshop1/w1/greyscale.js, width=775, height=255


As a second reference, an image with different colors and a lower quality.

# > :P5 sketch=/docs/sketches/workshop1/w1/greyscale2.js, width=775, height=255


#### Convertions - Videos

For the video, the loadPixels function was used, which allows obtaining each image of the video and the conversion functions were applied on them. The same functions were used to obtain the conversion of each pixel.

```javascript
function draw() {
  background(0);
  fingers.loadPixels();
  
  lienzo1.loadPixels();
  lienzo2.loadPixels();

  for (let x = 0; x <fingers.width; x++) {
    for (let y = 0; y < fingers.height; y++ ) {

      let loc = (x + y*fingers.width) * 4;
      let prom = (fingers.pixels[loc] + fingers.pixels[loc + 1] + fingers.pixels[loc + 2])/3;

      lienzo1.pixels[loc] = prom;
      lienzo1.pixels[loc + 1] = prom;
      lienzo1.pixels[loc + 2] = prom;
      lienzo1.pixels[loc + 3] = 255;

      let luma = 0.2126 * red(fingers.pixels[loc]) + 0.7152 * green(fingers.pixels[loc + 1]) + 0.0722 * blue(fingers.pixels[loc + 2]);

      lienzo2.pixels[loc] = luma;
      lienzo2.pixels[loc + 1] = luma;
      lienzo2.pixels[loc + 2] = luma;
      lienzo2.pixels[loc + 3] = 255;

    }
  }

  lienzo1.updatePixels();
  lienzo2.updatePixels();

  image(fingers,1,0); 
  image(lienzo1,fingers.width,0);
  image(lienzo2,fingers.width*2,0); 
}
```

All the conversion and the drawing process is carried out in the draw function, and a frame rate of 3 is established, since a higher number requires a GPU processing capacity that we do not have.


#### Results - Videos

On the canvas is drawn: the original video, the video with RGB average and the video with Luma,  respectively.

*Please click on the canvas to start playing the videos.*

> :P5 sketch=/docs/sketches/workshop1/w1/greyscaleVideo.js, width=775, height=255 

### Conclusions & future work

- It is necessary to consider the weight that each channel has on the final construction of the image, in order to obtain more accurate results.
- Although Y'709 provides a better result than RGB average, it is necessary to explore the other Luma standards (such as Y'2020) for even better results.
- In images with very few color variations and/or very low quality, the difference between RGB average and Luma tends to be imperceptible.
- Operations such as Gamma correction tend to substantially improve the results, however due to their high computational cost, linear combinations with good performance and a close result are preferred.

In the future, work focused on developing methods with such good results as Gamma correction, with lower computational costs, could be expected.


### References
 - [RGB](https://es.wikipedia.org/wiki/RGB)
 - [Grayscale](https://en.wikipedia.org/wiki/Grayscale)
 - [luma weighted sum](https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness)
 - [Convert an RGB Image to Grayscale](https://www.kdnuggets.com/2019/12/convert-rgb-image-grayscale.html)
 - [https://en.wikipedia.org/wiki/Gamma_correction](https://en.wikipedia.org/wiki/Gamma_correction)